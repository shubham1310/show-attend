{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Auto Encoder Example.\n",
    "Using an auto encoder on MNIST handwritten digits.\n",
    "References:\n",
    "    Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based\n",
    "    learning applied to document recognition.\" Proceedings of the IEEE,\n",
    "    86(11):2278-2324, November 1998.\n",
    "Links:\n",
    "    [MNIST Dataset] http://yann.lecun.com/exdb/mnist/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.contrib import rnn as contrib_rnn\n",
    "from tensorflow.python.framework import ops\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "\n",
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set both these false to start training\n",
    "generate_from_onehots = False  #set true to generate from custom one hots while testing\n",
    "_test_ = False\n",
    "\n",
    "def deconv2d(x, W, stride):\n",
    "    strides=[1, stride, stride, 1];\n",
    "    inshape = x.get_shape().as_list();\n",
    "    kernel_shape = W.get_shape().as_list();\n",
    "    output_shape = tf.pack([tf.shape(x)[0], tf.shape(x)[1]*strides[1], tf.shape(x)[2]*strides[2], kernel_shape[2]]);\n",
    "    #print(output_shape);\n",
    "    return tf.nn.conv2d_transpose(x, W, output_shape=output_shape, strides=strides, padding='SAME')\n",
    "    \n",
    "\n",
    "def weight_variable(shape, name=None):\n",
    "    #initial = tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "    #initial = tf.get_variable(name=name, shape=shape, regularizer=tf.contrib.layers.l2_regularizer(0.005))\n",
    "    initial = tf.get_variable(name, shape=shape,\n",
    "                        initializer=tf.contrib.layers.xavier_initializer())\n",
    "    return initial\n",
    "\n",
    "def bias_variable(shape, name=None):\n",
    "    #initial = tf.constant(0.1, shape=shape)\n",
    "    #return tf.Variable(initial, name=name)\n",
    "    return tf.get_variable(name, shape=shape,\n",
    "                        initializer=tf.constant_initializer(0.1))\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def py_func(func, inp, Tout, stateful=True, name=None, grad=None):\n",
    "    \n",
    "    # Need to generate a unique name to avoid duplicates:\n",
    "    rnd_name = 'PyFuncGrad' + str(np.random.randint(0, 1E+8))\n",
    "    \n",
    "    tf.RegisterGradient(rnd_name)(grad)  # see _MySquareGrad for grad example\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({\"PyFunc\": rnd_name}):\n",
    "        return tf.py_func(func, inp, Tout, stateful=stateful, name=name)\n",
    "\n",
    "def mycustomfunc(x):\n",
    "    one_hot_size_ = x.shape[-1]\n",
    "    probs = tf.constant(x)\n",
    "    probs = tf.reshape(probs,[-1, one_hot_size_])\n",
    "    if _test_:\n",
    "        oneHots = tf.one_hot(tf.argmax(probs, 1), one_hot_size_)\n",
    "    else:\n",
    "        logits = tf.log(probs/(1-probs))\n",
    "        indexes = tf.multinomial(logits, 1)\n",
    "        oneHots = tf.one_hot(indexes, one_hot_size_)\n",
    "    shape_ = list(x.shape)\n",
    "    oneHots = tf.reshape(oneHots, shape_)\n",
    "    sess_ = tf.Session()\n",
    "    with sess_.as_default():\n",
    "       ret_ = oneHots.eval()\n",
    "    return ret_\n",
    "    #np.random.choice(np.arange(2), p=x)\n",
    "    \n",
    "def myonehot(x, name=None):\n",
    "    with ops.name_scope(name, \"Myonehot\", [x]) as name:\n",
    "        sqr_x = py_func(mycustomfunc,\n",
    "                        [x],\n",
    "                        [tf.float32],\n",
    "                        name=name,\n",
    "                        grad=_MyonehotGrad)  # <-- here's the call to the gradient\n",
    "        return tf.reshape(sqr_x[0], tf.shape(x))\n",
    "    \n",
    "def _MyonehotGrad(op, grad):\n",
    "    x = op.inputs[0]\n",
    "    return grad#tf.constant(1.0, shape=shape_)#grad * 20 * x\n",
    "\n",
    "def _getBinary(x):\n",
    "    if _test_:\n",
    "        return x>0.5\n",
    "    return np.random.choice(np.arange(2), p=[1.0-x,x])\n",
    "\n",
    "def mycustombinarizer(x):\n",
    "    if _test_:\n",
    "        return x>0.5\n",
    "    \"\"\"binary_x = np.float32(np.reshape(np.array(map((lambda a: _getBinary(a)), x.reshape(x.size))),x.shape))\"\"\"\n",
    "    sess_ = tf.Session()\n",
    "    probs = tf.constant(x)\n",
    "    probs = tf.reshape(probs,[-1])\n",
    "    probs = tf.pack([1-probs, probs], axis=1)\n",
    "    probs = tf.log(probs/(1-probs))\n",
    "    indexes = tf.multinomial(probs, 1)\n",
    "    indexes = tf.cast(tf.reshape(indexes, list(x.shape)),tf.float32)\n",
    "    with sess_.as_default():\n",
    "       binary_x = indexes.eval()\n",
    "    return binary_x\n",
    "\n",
    "def binarizer(x, name=None):\n",
    "    with ops.name_scope(name, \"Binarizer\", [x]) as name:\n",
    "        sqr_x = py_func(mycustombinarizer,\n",
    "                        [x],\n",
    "                        [tf.float32],\n",
    "                        name=name,\n",
    "                        grad=_MyBinarizerGrad)  # <-- here's the call to the gradient\n",
    "        return tf.reshape(sqr_x[0], tf.shape(x))\n",
    "    \n",
    "def _MyBinarizerGrad(op, grad):\n",
    "    x = op.inputs[0]\n",
    "    return grad\n",
    "\n",
    "def newmyonehot(x):\n",
    "    one_hot_size_ = x.get_shape().as_list()\n",
    "    one_hot_size_ = one_hot_size_[-1];\n",
    "    probs = tf.reshape(x,[-1, one_hot_size_])\n",
    "    logits = tf.log(probs/(1-probs))\n",
    "    indexes = tf.multinomial(logits, 1)\n",
    "    oneHots = tf.one_hot(indexes, one_hot_size_)\n",
    "    oneHots = tf.reshape(oneHots, tf.shape(x))    \n",
    "    return oneHots\n",
    "\n",
    "def makeonehot(x):\n",
    "    t = tf.identity(x)\n",
    "    oneHots = t + tf.stop_gradient(newmyonehot(x) - t)\n",
    "    return oneHots\n",
    "\n",
    "#im = tf.constant(0.1, shape=[1,5,5,1])\n",
    "#net = slim.conv2d(im, 1,[3, 3], scope='aaa')\n",
    "#net = slim.conv2d(net, 1,[3, 3], scope='aaa')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.0003\n",
    "training_epochs = 500\n",
    "batch_size = 256\n",
    "display_step = 1\n",
    "examples_to_show = 10\n",
    "\n",
    "# Network Parameters\n",
    "#n_hidden_1 = 256 # 1st layer num features\n",
    "#n_hidden_2 = 128 # 2nd layer num features\n",
    "n_fc1 = 1024\n",
    "n_fc2 = 256\n",
    "n_fc3 = 3\n",
    "n_fc4 = 64\n",
    "n_fc5 = 256\n",
    "rnn_size = 256\n",
    "max_length = 5\n",
    "one_hot_size = 26\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "\n",
    "# tf Graph input (only pictures)\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_input])\n",
    "TrainTest = tf.placeholder(tf.float32,shape=[])\n",
    "y_classify = tf.placeholder(tf.float32, [None, 10])\n",
    "onehot_test = tf.placeholder(tf.int32, shape=[None, None, one_hot_size])\n",
    "epoch_no = tf.placeholder(tf.int32,shape=[])\n",
    "max_epoch = tf.placeholder(tf.int32,shape=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encoder_FC(x, netname, reuse):\n",
    "    with tf.variable_scope(netname+'encoder_FC') as scope:\n",
    "        if reuse == True:\n",
    "            scope.reuse_variables()\n",
    "        x_image = tf.reshape(x, [-1,28,28,1])\n",
    "        h_conv1 = tf.nn.relu(slim.conv2d(x_image, 32, [5, 5], scope='conv1'))\n",
    "        #h_conv1 = tf.nn.relu(conv2d(x_image, weight_variable([5, 5, 1, 32],'c1')) + bias_variable([32]))\n",
    "        h_pool1 = slim.max_pool2d(h_conv1, [2, 2], scope='pool1')\n",
    "        #h_pool1 = max_pool_2x2(h_conv1)\n",
    "        h_conv2 = tf.nn.relu(slim.conv2d(h_pool1, 64, [5, 5], scope='conv2'))\n",
    "        #h_conv2 = tf.nn.relu(conv2d(h_pool1, weight_variable([5, 5, 32, 64],'c2')) + bias_variable([64]))\n",
    "        h_pool2 = slim.max_pool2d(h_conv2, [2, 2], scope='pool2')\n",
    "        #h_pool2 = max_pool_2x2(h_conv2)\n",
    "        h_pool2_flat = slim.flatten(h_pool2, scope='pool2_flat')\n",
    "        #h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        h_fc1 = tf.nn.relu(slim.fully_connected(h_pool2_flat, n_fc1, scope='fc1'))\n",
    "        #h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, weight_variable([7*7*64, n_fc1],'fc1')) + bias_variable([n_fc1]))\n",
    "        h_fc2 = slim.fully_connected(h_fc1, n_fc2, scope='fc2', activation_fn=None)\n",
    "        #h_fc2 = tf.nn.relu(tf.matmul(h_fc1, weight_variable([n_fc1,n_fc2],'fc2')) + bias_variable([n_fc2]))\n",
    "        return h_fc2\n",
    "    \n",
    "def encoder_RNN(x, netname, reuse):\n",
    "    with tf.variable_scope(netname+'encoder_RNN') as scope:\n",
    "        if reuse == True:\n",
    "            scope.reuse_variables()\n",
    "        x = tf.cast(x,tf.float32)\n",
    "        data = tf.pack([x]*max_length);\n",
    "        data = tf.transpose(data,[1,0,2])\n",
    "        cell_encoder = tf.nn.rnn_cell.GRUCell(rnn_size)\n",
    "        output, _ = tf.nn.dynamic_rnn(cell_encoder, data, dtype=tf.float32)\n",
    "        output = tf.reshape(output, [-1, rnn_size])\n",
    "        rnn_predictions = tf.nn.softmax(slim.fully_connected(output, one_hot_size, scope='rnn_softmax'))\n",
    "        rnn_predictions = tf.reshape(rnn_predictions, [-1, max_length, one_hot_size])\n",
    "        rnn_one_hots = makeonehot(rnn_predictions)\n",
    "        print (rnn_one_hots.get_shape())\n",
    "        return rnn_one_hots, rnn_predictions\n",
    "    \n",
    "def encoder(x, netname, reuse):\n",
    "    h_fc2_ = encoder_FC(x, netname, reuse)\n",
    "    rnn_one_hots_, rnn_predictions_ = encoder_RNN(h_fc2_, netname, reuse)\n",
    "    return rnn_one_hots_, h_fc2_, rnn_predictions_\n",
    "    \n",
    "\n",
    "# Building the decoder\n",
    "def decoder_FC(x, netname, train, reuse):\n",
    "    with tf.variable_scope(netname+'decoder_FC')as scope:\n",
    "        if reuse == True:\n",
    "            scope.reuse_variables()\n",
    "        x = tf.cast(x,tf.float32)\n",
    "        x = x + (tf.random_uniform(tf.shape(x))-0.5)*train\n",
    "        h_fc4 = tf.nn.relu(slim.fully_connected(x, n_fc1, scope='fc4'))\n",
    "        #h_fc4 = tf.nn.relu(tf.matmul(x, weight_variable([n_fc2,n_fc1],'fc4')) + bias_variable([n_fc1]))\n",
    "        h_fc5 = tf.nn.relu(slim.fully_connected(x, 7*7*64, scope='fc5'))\n",
    "        #h_fc5 = tf.nn.relu(tf.matmul(x, weight_variable([n_fc2,7*7*64],'fc5')) + bias_variable([7*7*64]))\n",
    "        h_fc5_square = tf.reshape(h_fc5, [-1, 7, 7, 64])\n",
    "        #h_deconv1 = tf.nn.relu(slim.conv2d_transpose(h_fc5_square, 32, [5, 5], stride=2, scope='deconv1'))        \n",
    "        h_deconv1 = tf.nn.relu(deconv2d(h_fc5_square, weight_variable([5, 5, 32, 64],'deconv1'), 2) + bias_variable([32],'deconv1_b'))\n",
    "        #h_deconv2 = tf.nn.sigmoid(slim.conv2d_transpose(h_deconv1, 1, [5, 5], stride=2, scope='deconv2'))\n",
    "        h_deconv2 = tf.nn.sigmoid(deconv2d(h_deconv1, weight_variable([5, 5, 1, 32],'deconv2'), 2) + bias_variable([1],'deconv2_b'))\n",
    "        return tf.reshape(h_deconv2, [-1, 784])\n",
    "    \n",
    "   \n",
    "# Building the decoder\n",
    "def decoder_RNN(x, netname, reuse):\n",
    "    with tf.variable_scope(netname+'decoder_RNN')as scope:\n",
    "        if reuse == True:\n",
    "            scope.reuse_variables()\n",
    "        cell_decoder = tf.nn.rnn_cell.GRUCell(rnn_size)\n",
    "        output_dec, _ = tf.nn.dynamic_rnn(cell_decoder, tf.cast(x,tf.float32), dtype=tf.float32)\n",
    "        output_dec = tf.transpose(output_dec, [1, 0, 2])\n",
    "        output_dec = tf.gather(output_dec, tf.shape(output_dec)[0] - 1)\n",
    "        #output_dec = tf.nn.relu(tf.matmul(output_dec, weights['decoder_W_fc3']) + biases['decoder_b_fc3'])\n",
    "        output_dec = slim.fully_connected(output_dec, n_fc5, scope='dfc3')\n",
    "        output_dec = slim.fully_connected(output_dec, n_fc5, scope='dfc4',activation_fn=None)\n",
    "        return output_dec\n",
    "\n",
    "    \n",
    "def decoder_RNN_FC(x, netname, reuse):\n",
    "    output_dec = decoder_RNN(x, netname, reuse);\n",
    "    return decoder_FC(output_dec, netname, 0, reuse);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if generate_from_onehots == False:\n",
    "    # Construct model\n",
    "    _1_hot_net1, encoder_FC_256_net1, predprob_net1 = encoder(X, 'net1', False)\n",
    "    decoder_RNN_256_net1 = decoder_RNN(_1_hot_net1, 'net1', False)\n",
    "    #encoder_op_net1 = encoder_FC(X, 'net1', False)\n",
    "    decoder_FC_image_net1 = decoder_FC(encoder_FC_256_net1, 'net1', TrainTest, False)\n",
    "    decoder_RNN_FC_image_net1 = decoder_RNN_FC(_1_hot_net1, 'net1', True)\n",
    "    \n",
    "    \n",
    "    _1_hot_net2, encoder_FC_256_net2, predprob_net2 = encoder(X, 'net2', False)\n",
    "    decoder_RNN_256_net2 = decoder_RNN(_1_hot_net2, 'net2', False)\n",
    "    decoder_FC_image_net2 = decoder_FC(encoder_FC_256_net2, 'net2', TrainTest, False)\n",
    "    decoder_RNN_FC_image_net2 = decoder_RNN_FC(_1_hot_net2, 'net2', True)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred_image_net1 = decoder_FC_image_net1\n",
    "    #y_pred_image_net1 = decoder_RNN_FC_image_net1\n",
    "    y_pred_RNN_256_net1 = decoder_RNN_256_net1\n",
    "    \n",
    "    y_pred_image_net2 = decoder_FC_image_net2\n",
    "    #y_pred_image_net2 = decoder_RNN_FC_image_net2\n",
    "    y_pred_RNN_256_net2 = decoder_RNN_256_net2\n",
    "    # Targets (Labels) are the input data.\n",
    "    y_true_image = X\n",
    "\n",
    "else:\n",
    "    decoder_op = decoder_RNN(onehot_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if generate_from_onehots == False:\n",
    "     # Define loss and optimizer, minimize the squared error\n",
    "    #cost = cost1+cost2\n",
    "    #_1_hot__ = tf.reshape(_1_hot, [-1, one_hot_size])   # this is weird .. uncommenting this line prevents convergence\n",
    "    #cost3 = tf.reduce_mean(tf.pow(1-(tf.reduce_sum(_1_hot__,reduction_indices=[1])),2))\n",
    "    #cost3 = tf.reduce_mean(-tf.log(tf.reduce_sum(_1_hot__,reduction_indices=[1])))\n",
    "    cost_image_net1 = tf.reduce_mean(tf.pow(y_true_image - y_pred_image_net1, 2))\n",
    "    cost_image_net2 = tf.reduce_mean(tf.pow(y_true_image - y_pred_image_net2, 2))\n",
    "    \n",
    "    \n",
    "    cost_256_l2_net1 = tf.pow(encoder_FC_256_net1 - y_pred_RNN_256_net1, 2)\n",
    "    cost_256_l1_net1 = tf.abs(encoder_FC_256_net1 - y_pred_RNN_256_net1)\n",
    "    cost_256_l2_net2 = tf.pow(encoder_FC_256_net2 - y_pred_RNN_256_net2, 2)\n",
    "    cost_256_l1_net2 = tf.abs(encoder_FC_256_net2 - y_pred_RNN_256_net2)\n",
    "##    (1-sigmoid(1500(abs(x)-1)))*abs(x) + (sigmoid(1500(abs(x)-1)))*(x*x/2+0.5)\n",
    "#     cost_256_net1= tf.reduce_mean(\n",
    "#                     (1.0-tf.sigmoid(1500*(cost_256_l1_net1-1.0)))*cost_256_l1_net1 + \n",
    "#                     (  tf.sigmoid(1500*(cost_256_l1_net1-1.0)))*(cost_256_l2_net1/2.0+0.5)\n",
    "#                     )\n",
    "#     cost_256_net2= tf.reduce_mean(\n",
    "#                     (1.0-tf.sigmoid(1500*(cost_256_l1_net2-1.0)))*cost_256_l1_net2 + \n",
    "#                     (  tf.sigmoid(1500*(cost_256_l1_net2-1.0)))*(cost_256_l2_net2/2.0+0.5)\n",
    "#                     )\n",
    "\n",
    "    cost_256_net1= tf.reduce_mean(cost_256_l2_net1)\n",
    "    cost_256_net2= tf.reduce_mean(cost_256_l2_net2)    \n",
    "    #cost_1hot_match = tf.reduce_mean(tf.pow(_1_hot_net1 - _1_hot_net2, 2))\n",
    "    cost_1hot_match = tf.reduce_mean(tf.pow(predprob_net1 - predprob_net2, 2))\n",
    "\n",
    "    \n",
    "    xv=tf.cast(epoch_no,tf.float32)\n",
    "    xm=tf.cast(max_epoch,tf.float32)\n",
    "#     startLow= tf.sigmoid((xv-xm/2)/5)\n",
    "    startLow= 2\n",
    "    startHigh= 1 \n",
    "    \n",
    "    cost = cost_image_net1 + cost_256_net1 + cost_image_net2 + cost_256_net2 + cost_1hot_match\n",
    "    costdisjoint = cost_image_net1*startHigh + cost_256_net1*startLow + cost_image_net2*startHigh + cost_256_net2*startLow\n",
    "    totalcost = costdisjoint+cost_1hot_match\n",
    "    #cost = cost + tf.reduce_mean(-tf.reduce_sum(y_classify * tf.log(y_pred_classify), reduction_indices=[1]))\n",
    "    #optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "    #optimizerdj = tf.train.AdamOptimizer(learning_rate).minimize(costdisjoint)\n",
    "    \n",
    "    var1s = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='net1encoder_FC')\n",
    "    var1s = var1s+tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='net1decoder_FC')\n",
    "    \n",
    "    var2s = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='net1encoder_RNN')\n",
    "    var2s = var2s+tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='net1decoder_RNN')\n",
    "    optimizer1 = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "        cost_image_net1 + cost_256_net1, var_list=var1s+var2s)\n",
    "    #optimizer2 = tf.train.AdamOptimizer(learning_rate).minimize(cost2,var_list=var2s)\n",
    "    \n",
    "    var3s = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='net2encoder_FC')\n",
    "    var3s = var3s+tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='net2decoder_FC')\n",
    "    \n",
    "    var4s = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='net2encoder_RNN')\n",
    "    var4s = var4s+tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='net2decoder_RNN')\n",
    "    optimizer3 = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "        cost_image_net2 + cost_256_net2, var_list=var3s+var4s)\n",
    "    #optimizer4 = tf.train.AdamOptimizer(learning_rate).minimize(cost4,var_list=var4s)\n",
    "    \n",
    "    var5s = var2s+var4s\n",
    "    optimizer5 = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "        cost_1hot_match + cost_256_net1 + cost_256_net2, var_list=var5s)\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    #cost2 = tf.reduce_mean(tf.pow(decoder_op_one_hot_only - y_pred, 2))\n",
    "    optimizerdj = tf.train.AdamOptimizer(learning_rate).minimize(costdisjoint,var_list = var1s+var3s+var2s+var4s)\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(totalcost,var_list = var1s+var3s+var2s+var4s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Launch the graph\n",
    "# Using InteractiveSession (more convenient while using Notebooks)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawoutput():\n",
    "    encode_decode, encode_decode2, onehots, predprob_, \\\n",
    "    encode_decode_net2, encode_decode2_net2, onehots_net2, predprob__net2 = sess.run( \\\n",
    "        [y_pred_image_net1, decoder_RNN_FC_image_net1, _1_hot_net1, predprob_net1, \\\n",
    "         y_pred_image_net2, decoder_RNN_FC_image_net2, _1_hot_net2, predprob_net2], \\\n",
    "        feed_dict={X: mnist.test.images[:examples_to_show], TrainTest:0.0})\n",
    "    #encode_decode, encode_decode2, onehots, predprob_ = sess.run( \\\n",
    "    #    [y_pred_image_net1, decoder_RNN_FC_image_net1, _1_hot_net1, predprob_net1], \\\n",
    "    #    feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    print(np.argmax(onehots,2))\n",
    "    print(np.max(predprob_,2))\n",
    "    #print(cost2_)\n",
    "    # Compare original images with their reconstructions\n",
    "    f, a = plt.subplots(4, examples_to_show, figsize=(examples_to_show, 3))\n",
    "    for i in range(examples_to_show):\n",
    "        a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "        a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))\n",
    "        a[2][i].imshow(np.reshape(encode_decode2[i], (28, 28)))\n",
    "        a[3][i].imshow(np.reshape(encode_decode2_net2[i], (28, 28)))\n",
    "    f.show()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if generate_from_onehots == False and _test_==False:\n",
    "    training_epochs = 200\n",
    "    examples_to_show = 11\n",
    "\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _,c1,c2,c3,c4,c5 = sess.run(\n",
    "                [optimizer,cost_image_net1,cost_256_net1,cost_image_net2,cost_256_net2,cost_1hot_match],\n",
    "                feed_dict={X: batch_xs, y_classify: batch_ys, \n",
    "                           TrainTest:1.0, epoch_no:epoch, max_epoch: training_epochs})\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1),\n",
    "                  #\"cost=\", \"{:.9f}\".format(c),\n",
    "                  \"cost1=\", \"{:.9f}\".format(c1),\n",
    "                  \"cost2=\", \"{:.9f}\".format(c2),\n",
    "                  \"cost3=\", \"{:.9f}\".format(c3),\n",
    "                  \"cost4=\", \"{:.9f}\".format(c4),\n",
    "                  \"cost5=\", \"{:.9f}\".format(c5),\n",
    "                  )\n",
    "        if (epoch+1) % (display_step*10) == 0:\n",
    "            drawoutput()\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Applying encode and decode over test set\n",
    "    encode_decode = sess.run(\n",
    "        y_pred, feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    # Compare original images with their reconstructions\n",
    "    f, a = plt.subplots(2, examples_to_show, figsize=(examples_to_show, 2))\n",
    "    for i in range(examples_to_show):\n",
    "        a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "        a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))\n",
    "    f.show()\n",
    "    plt.draw()\n",
    "    #plt.waitforbuttonpress() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(write_version=tf.train.SaverDef.V2)\n",
    "if generate_from_onehots == False and _test_==False:\n",
    "    save_path = saver.save(sess, \"./model_256_msarkar_lang.ckpt\")\n",
    "else:\n",
    "    saver.restore(sess, \"./model_256_msarkar_lang.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if generate_from_onehots == True:\n",
    "    # TESTING CUSTOM\n",
    "    # Applying encode and decode over test set\n",
    "\n",
    "    onehots = np.zeros((1,3,20))\n",
    "    pos = np.random.randint(20);\n",
    "    prob = np.random.randint(2);\n",
    "    onehots[0][0][(1-prob)*pos + prob*np.random.randint(20)] = 1;\n",
    "    prob = np.random.randint(2);\n",
    "    onehots[0][1][(1-prob)*pos + prob*np.random.randint(20)] = 1;\n",
    "    prob = np.random.randint(2);\n",
    "    onehots[0][2][(1-prob)*pos + prob*np.random.randint(20)] = 1;\n",
    "    \n",
    "    # Manually set the sentence \n",
    "    # edit this to generate new sentence .. the values are in range(one_hot_size) \n",
    "    # sentence length is not bounded\n",
    "    sentence = [1];   \n",
    "    onehots = np.zeros((1,len(sentence),20))\n",
    "    for i in range(len(sentence)):\n",
    "        onehots[0][i][sentence[i]] = 1;\n",
    "    \n",
    "    print(np.argmax(onehots,2))\n",
    "    encode_decode = sess.run(\n",
    "        decoder_op, feed_dict={onehot_test: onehots})\n",
    "    #print(np.argmax(onehots,2))\n",
    "    # Compare original images with their reconstructions\n",
    "    f, a = plt.subplots(1, onehots.shape[0]+1, figsize=(onehots.shape[0]*3, 2))\n",
    "    for i in range(onehots.shape[0]):\n",
    "        #a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "        a[i].imshow(np.reshape(encode_decode[i], (28, 28)))\n",
    "    f.show()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if generate_from_onehots == False:\n",
    "    # Result\n",
    "    # Applying encode and decode over test set\n",
    "    #encode_decode, onehots, encode_decode_onehotonly, cost2_ = sess.run(\n",
    "    #    [y_pred, encoder_op, decoder_op_one_hot_only, cost2], feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    \n",
    "    encode_decode, encode_decode2, onehots, predprob_, \\\n",
    "    encode_decode_net2, encode_decode2_net2, onehots_net2, predprob__net2 = sess.run( \\\n",
    "        [y_pred_image_net1, decoder_RNN_FC_image_net1, _1_hot_net1, predprob_net1, \\\n",
    "         y_pred_image_net2, decoder_RNN_FC_image_net2, _1_hot_net2, predprob_net2], \\\n",
    "        feed_dict={X: mnist.test.images[:examples_to_show], TrainTest:0.0})\n",
    "    #encode_decode, encode_decode2, onehots, predprob_ = sess.run( \\\n",
    "    #    [y_pred_image_net1, decoder_RNN_FC_image_net1, _1_hot_net1, predprob_net1], \\\n",
    "    #    feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    print(np.argmax(onehots,2))\n",
    "    print(np.max(predprob_,2))\n",
    "    #print(cost2_)\n",
    "    # Compare original images with their reconstructions\n",
    "    f, a = plt.subplots(4, examples_to_show, figsize=(examples_to_show, 3))\n",
    "    for i in range(examples_to_show):\n",
    "        a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "        a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))\n",
    "        a[2][i].imshow(np.reshape(encode_decode2[i], (28, 28)))\n",
    "        a[3][i].imshow(np.reshape(encode_decode2_net2[i], (28, 28)))\n",
    "    f.show()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#cost = costdisjoint + 0.1*cost5  after 20 iterations\n",
    "\n",
    "\"\"\"\n",
    "Epoch: 0001 cost1= 0.060610365 cost2= 0.001456601 cost3= 0.063119449 cost4= 0.000905316 cost5= 0.048858173\n",
    "Epoch: 0002 cost1= 0.038265381 cost2= 0.003614630 cost3= 0.044919856 cost4= 0.003158854 cost5= 0.020252405\n",
    "Epoch: 0003 cost1= 0.024723999 cost2= 0.003737362 cost3= 0.026506023 cost4= 0.003780622 cost5= 0.026562501\n",
    "Epoch: 0004 cost1= 0.018576309 cost2= 0.002980163 cost3= 0.019376988 cost4= 0.003027871 cost5= 0.021814905\n",
    "Epoch: 0005 cost1= 0.015814539 cost2= 0.002824710 cost3= 0.016395586 cost4= 0.002846907 cost5= 0.019350965\n",
    "Epoch: 0006 cost1= 0.012713787 cost2= 0.002390323 cost3= 0.013109592 cost4= 0.002493173 cost5= 0.019350963\n",
    "Epoch: 0007 cost1= 0.011025983 cost2= 0.002131242 cost3= 0.011436282 cost4= 0.002160230 cost5= 0.020372596\n",
    "Epoch: 0008 cost1= 0.010698613 cost2= 0.001968088 cost3= 0.011302998 cost4= 0.001989576 cost5= 0.027043272\n",
    "Epoch: 0009 cost1= 0.009618663 cost2= 0.001801275 cost3= 0.010104033 cost4= 0.001836486 cost5= 0.023918271\n",
    "Epoch: 0010 cost1= 0.008725640 cost2= 0.001585961 cost3= 0.009267062 cost4= 0.001644548 cost5= 0.023557693\n",
    "Epoch: 0011 cost1= 0.008295461 cost2= 0.001504187 cost3= 0.008877432 cost4= 0.001551532 cost5= 0.024519233\n",
    "Epoch: 0012 cost1= 0.007812739 cost2= 0.001404112 cost3= 0.008684461 cost4= 0.001432679 cost5= 0.024519231\n",
    "Epoch: 0013 cost1= 0.007785469 cost2= 0.001362351 cost3= 0.008305097 cost4= 0.001438453 cost5= 0.026081732\n",
    "Epoch: 0014 cost1= 0.007566055 cost2= 0.001269917 cost3= 0.008127766 cost4= 0.001308516 cost5= 0.026622597\n",
    "Epoch: 0015 cost1= 0.006859084 cost2= 0.001158703 cost3= 0.007357582 cost4= 0.001225068 cost5= 0.026382212\n",
    "Epoch: 0016 cost1= 0.006784092 cost2= 0.001126843 cost3= 0.007232355 cost4= 0.001184428 cost5= 0.025600962\n",
    "Epoch: 0017 cost1= 0.006202817 cost2= 0.000993841 cost3= 0.006698935 cost4= 0.001042053 cost5= 0.027403846\n",
    "Epoch: 0018 cost1= 0.006432699 cost2= 0.000996745 cost3= 0.007024150 cost4= 0.001016795 cost5= 0.027824519\n",
    "Epoch: 0019 cost1= 0.005964880 cost2= 0.000916859 cost3= 0.006544244 cost4= 0.000965654 cost5= 0.028185096\n",
    "Epoch: 0020 cost1= 0.005557414 cost2= 0.000886401 cost3= 0.005953393 cost4= 0.000921355 cost5= 0.027103368\n",
    "Optimization Finished!\n",
    "\"\"\"\n",
    "\n",
    "if generate_from_onehots == False:\n",
    "    # Result\n",
    "    # Applying encode and decode over test set\n",
    "    #encode_decode, onehots, encode_decode_onehotonly, cost2_ = sess.run(\n",
    "    #    [y_pred, encoder_op, decoder_op_one_hot_only, cost2], feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    \n",
    "    encode_decode, encode_decode2, onehots, predprob_, \\\n",
    "    encode_decode_net2, encode_decode2_net2, onehots_net2, predprob__net2 = sess.run( \\\n",
    "        [y_pred_image_net1, decoder_RNN_FC_image_net1, _1_hot_net1, predprob_net1, \\\n",
    "         y_pred_image_net2, decoder_RNN_FC_image_net2, _1_hot_net2, predprob_net2], \\\n",
    "        feed_dict={X: mnist.test.images[:examples_to_show], TrainTest:0.0})\n",
    "    #encode_decode, encode_decode2, onehots, predprob_ = sess.run( \\\n",
    "    #    [y_pred_image_net1, decoder_RNN_FC_image_net1, _1_hot_net1, predprob_net1], \\\n",
    "    #    feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    print(np.argmax(onehots,2))\n",
    "    print(np.max(predprob_,2))\n",
    "    #print(cost2_)\n",
    "    # Compare original images with their reconstructions\n",
    "    f, a = plt.subplots(4, examples_to_show, figsize=(examples_to_show, 3))\n",
    "    for i in range(examples_to_show):\n",
    "        a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "        a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))\n",
    "        a[2][i].imshow(np.reshape(encode_decode2[i], (28, 28)))\n",
    "        a[3][i].imshow(np.reshape(encode_decode2_net2[i], (28, 28)))\n",
    "    f.show()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if generate_from_onehots == False:\n",
    "    # display plots in this notebook\n",
    "    # Applying encode and decode over test set\n",
    "    print('****Looking at some TRAINING samples as well : useful to check overfitting')\n",
    "    #ind = range(examples_to_show);\n",
    "    #print(ind)\n",
    "    #np.random.shuffle(ind);\n",
    "    #print(ind)\n",
    "    images__ = mnist.train.images[:examples_to_show];\n",
    "    encode_decode, encode_decode2 = sess.run(\n",
    "        [y_pred, decoder_RNN_FC], feed_dict={X: images__, TrainTest:0.0})\n",
    "    #print(cost2_)\n",
    "    #print(sess.run(cost, feed_dict={X: mnist.train.images[:examples_to_show]}))\n",
    "    # Compare original images with their reconstructions\n",
    "    f, a = plt.subplots(3, examples_to_show, figsize=(examples_to_show, 2))\n",
    "    for i in range(examples_to_show):\n",
    "        a[0][i].imshow(np.reshape(images__[i], (28, 28)))\n",
    "        a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))\n",
    "        a[2][i].imshow(np.reshape(encode_decode2[i], (28, 28)))\n",
    "    f.show()\n",
    "    plt.draw()\n",
    "    #plt.waitforbuttonpress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#cost = costdisjoint + 10*cost5   after 30 iterations\n",
    "\n",
    "\"\"\"\n",
    "Epoch: 0001 cost1= 0.062787324 cost2= 0.001301013 cost3= 0.062241048 cost4= 0.001284453 cost5= 0.074579328\n",
    "Epoch: 0002 cost1= 0.041112404 cost2= 0.003722330 cost3= 0.035201248 cost4= 0.004214905 cost5= 0.073677883\n",
    "Epoch: 0003 cost1= 0.025945349 cost2= 0.003724482 cost3= 0.023045212 cost4= 0.003668737 cost5= 0.074038468\n",
    "Epoch: 0004 cost1= 0.018444441 cost2= 0.003338973 cost3= 0.017491074 cost4= 0.003249121 cost5= 0.073798075\n",
    "Epoch: 0005 cost1= 0.014570432 cost2= 0.002813716 cost3= 0.014376300 cost4= 0.002773168 cost5= 0.074579328\n",
    "Epoch: 0006 cost1= 0.013128826 cost2= 0.002536717 cost3= 0.013258265 cost4= 0.002525580 cost5= 0.074278846\n",
    "Epoch: 0007 cost1= 0.011637468 cost2= 0.002239972 cost3= 0.011527496 cost4= 0.002250951 cost5= 0.073437497\n",
    "Epoch: 0008 cost1= 0.010718588 cost2= 0.002066593 cost3= 0.010292327 cost4= 0.002039759 cost5= 0.073858172\n",
    "Epoch: 0009 cost1= 0.009763879 cost2= 0.001874423 cost3= 0.009422855 cost4= 0.001834712 cost5= 0.074278846\n",
    "Epoch: 0010 cost1= 0.008507368 cost2= 0.001708979 cost3= 0.008298178 cost4= 0.001659426 cost5= 0.074399039\n",
    "Epoch: 0011 cost1= 0.008081965 cost2= 0.001573510 cost3= 0.007576883 cost4= 0.001523594 cost5= 0.074459136\n",
    "Epoch: 0012 cost1= 0.007761152 cost2= 0.001510136 cost3= 0.007446318 cost4= 0.001423335 cost5= 0.074038461\n",
    "Epoch: 0013 cost1= 0.007857277 cost2= 0.001412459 cost3= 0.007283356 cost4= 0.001346507 cost5= 0.074158661\n",
    "Epoch: 0014 cost1= 0.007329797 cost2= 0.001313280 cost3= 0.006817589 cost4= 0.001240621 cost5= 0.073918283\n",
    "Epoch: 0015 cost1= 0.006638652 cost2= 0.001229314 cost3= 0.006049460 cost4= 0.001169476 cost5= 0.073677897\n",
    "Epoch: 0016 cost1= 0.006283126 cost2= 0.001150892 cost3= 0.006064247 cost4= 0.001075986 cost5= 0.073918268\n",
    "Epoch: 0017 cost1= 0.006149262 cost2= 0.001107690 cost3= 0.005871051 cost4= 0.001026551 cost5= 0.074038461\n",
    "Epoch: 0018 cost1= 0.005928580 cost2= 0.001031580 cost3= 0.005745222 cost4= 0.000952911 cost5= 0.074278846\n",
    "Epoch: 0019 cost1= 0.005887466 cost2= 0.000971276 cost3= 0.005562180 cost4= 0.000896822 cost5= 0.073918268\n",
    "Epoch: 0020 cost1= 0.005591392 cost2= 0.000946584 cost3= 0.005346459 cost4= 0.000866824 cost5= 0.074098557\n",
    "Epoch: 0021 cost1= 0.005831487 cost2= 0.000879509 cost3= 0.005578282 cost4= 0.000799240 cost5= 0.073918268\n",
    "Epoch: 0022 cost1= 0.005558632 cost2= 0.000845184 cost3= 0.005242722 cost4= 0.000771731 cost5= 0.073557705\n",
    "Epoch: 0023 cost1= 0.005799457 cost2= 0.000819442 cost3= 0.005414273 cost4= 0.000747545 cost5= 0.073137015\n",
    "Epoch: 0024 cost1= 0.005268201 cost2= 0.000785169 cost3= 0.004954715 cost4= 0.000703301 cost5= 0.074519232\n",
    "Epoch: 0025 cost1= 0.005229989 cost2= 0.000735353 cost3= 0.005001098 cost4= 0.000662482 cost5= 0.074098557\n",
    "Epoch: 0026 cost1= 0.005055581 cost2= 0.000710857 cost3= 0.004737457 cost4= 0.000655101 cost5= 0.074579328\n",
    "Epoch: 0027 cost1= 0.004539810 cost2= 0.000665494 cost3= 0.004221438 cost4= 0.000596062 cost5= 0.073798075\n",
    "Epoch: 0028 cost1= 0.004902592 cost2= 0.000651156 cost3= 0.004573327 cost4= 0.000580378 cost5= 0.074158654\n",
    "Epoch: 0029 cost1= 0.004658089 cost2= 0.000632667 cost3= 0.004485802 cost4= 0.000567020 cost5= 0.073437497\n",
    "Epoch: 0030 cost1= 0.004598193 cost2= 0.000599556 cost3= 0.004344812 cost4= 0.000534149 cost5= 0.074399039\n",
    "Optimization Finished!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "if generate_from_onehots == False:\n",
    "    # Result\n",
    "    # Applying encode and decode over test set\n",
    "    #encode_decode, onehots, encode_decode_onehotonly, cost2_ = sess.run(\n",
    "    #    [y_pred, encoder_op, decoder_op_one_hot_only, cost2], feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    \n",
    "    encode_decode, encode_decode2, onehots, predprob_, \\\n",
    "    encode_decode_net2, encode_decode2_net2, onehots_net2, predprob__net2 = sess.run( \\\n",
    "        [y_pred_image_net1, decoder_RNN_FC_image_net1, _1_hot_net1, predprob_net1, \\\n",
    "         y_pred_image_net2, decoder_RNN_FC_image_net2, _1_hot_net2, predprob_net2], \\\n",
    "        feed_dict={X: mnist.test.images[:examples_to_show], TrainTest:0.0})\n",
    "    #encode_decode, encode_decode2, onehots, predprob_ = sess.run( \\\n",
    "    #    [y_pred_image_net1, decoder_RNN_FC_image_net1, _1_hot_net1, predprob_net1], \\\n",
    "    #    feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    print(np.argmax(onehots,2))\n",
    "    print(np.max(predprob_,2))\n",
    "    #print(cost2_)\n",
    "    # Compare original images with their reconstructions\n",
    "    f, a = plt.subplots(4, examples_to_show, figsize=(examples_to_show, 3))\n",
    "    for i in range(examples_to_show):\n",
    "        a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "        a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))\n",
    "        a[2][i].imshow(np.reshape(encode_decode2[i], (28, 28)))\n",
    "        a[3][i].imshow(np.reshape(encode_decode2_net2[i], (28, 28)))\n",
    "    f.show()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#TRAINIG SET\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if generate_from_onehots == False:\n",
    "    # Result\n",
    "    # Applying encode and decode over test set\n",
    "    #encode_decode, onehots, encode_decode_onehotonly, cost2_ = sess.run(\n",
    "    #    [y_pred, encoder_op, decoder_op_one_hot_only, cost2], feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    \n",
    "    encode_decode, encode_decode2, onehots, predprob_, \\\n",
    "    encode_decode_net2, encode_decode2_net2, onehots_net2, predprob__net2 = sess.run( \\\n",
    "        [y_pred_image_net1, decoder_RNN_FC_image_net1, _1_hot_net1, predprob_net1, \\\n",
    "         y_pred_image_net2, decoder_RNN_FC_image_net2, _1_hot_net2, predprob_net2], \\\n",
    "        feed_dict={X: mnist.train.images[:examples_to_show], TrainTest:0.0})\n",
    "    #encode_decode, encode_decode2, onehots, predprob_ = sess.run( \\\n",
    "    #    [y_pred_image_net1, decoder_RNN_FC_image_net1, _1_hot_net1, predprob_net1], \\\n",
    "    #    feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    print(np.argmax(onehots,2))\n",
    "    print(np.max(predprob_,2))\n",
    "    #print(cost2_)\n",
    "    # Compare original images with their reconstructions\n",
    "    f, a = plt.subplots(4, examples_to_show, figsize=(examples_to_show, 3))\n",
    "    for i in range(examples_to_show):\n",
    "        a[0][i].imshow(np.reshape(mnist.train.images[i], (28, 28)))\n",
    "        a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))\n",
    "        a[2][i].imshow(np.reshape(encode_decode2[i], (28, 28)))\n",
    "        a[3][i].imshow(np.reshape(encode_decode2_net2[i], (28, 28)))\n",
    "    f.show()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
